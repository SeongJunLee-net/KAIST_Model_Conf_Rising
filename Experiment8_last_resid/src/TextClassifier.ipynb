{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BART Parameter Spec\n",
    "\t\n",
    "24-layer, 1024-hidden, 16-heads, 406M parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "\n",
    "# BART 모델과 토크나이저 로드\n",
    "model_name = 'facebook/bart-large'\n",
    "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    0, 50118,  2264,    16,     5,   723,    12,  4483,  4286,     9,\n",
       "             5,  1385,   128, 19195,   140, 35661, 50118,   250,    35, 18404,\n",
       "         50118,  2264,    16,     5,   723,    12,  4483,  4286,     9,     5,\n",
       "          1385,   128, 14031, 35661, 50118,   250,    35,  5857, 50118,  2264,\n",
       "            16,     5,   723,    12,  4483,  4286,     9,     5,  1385,   128,\n",
       "         36675, 27699, 35661, 50118,   250,    35, 50264, 50118,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# CoT 프롬프트 정의\n",
    "# CoT와 Few-shot 예시를 포함한 프롬프트 정의\n",
    "prompt = f\"\"\"\n",
    "What is the higher-level concept of the term 'Donald Trump'?\n",
    "A: Person\n",
    "What is the higher-level concept of the term 'Canada'?\n",
    "A: Nation\n",
    "What is the higher-level concept of the term 'Apartment'?\n",
    "A: {tokenizer.mask_token}\n",
    "\"\"\"\n",
    "\n",
    "# 프롬프트를 토큰화하고 입력 시퀀스 생성\n",
    "inputs = tokenizer(prompt, return_tensors='pt')\n",
    "\n",
    "inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sjlee/miniconda3/envs/sj_virtual/lib/python3.8/site-packages/transformers/generation/configuration_utils.py:588: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n",
      "/home/sjlee/miniconda3/envs/sj_virtual/lib/python3.8/site-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the higher-level concept of the term 'Donald Trump'? fixme\n"
     ]
    }
   ],
   "source": [
    "# 모델을 사용하여 추론 수행\n",
    "outputs = model.generate(**inputs,num_beams=1, early_stopping=True)\n",
    "\n",
    "# 생성된 응답을 디코딩\n",
    "response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ne_chunk,word_tokenize,pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Apple', 'is', 'good', 'company']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(\"Apple is good company\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WordNet을 이용한 개념의 상위개념 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/sjlee/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/sjlee/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('speed.n.01'),\n",
       " Synset('speed.n.02'),\n",
       " Synset('speed.n.03'),\n",
       " Synset('focal_ratio.n.01'),\n",
       " Synset('amphetamine.n.01'),\n",
       " Synset('rush.v.01'),\n",
       " Synset('accelerate.v.01'),\n",
       " Synset('travel_rapidly.v.01'),\n",
       " Synset('speed.v.04'),\n",
       " Synset('accelerate.v.02')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = \"dinosour\"\n",
    "synsets = wn.synsets(word)\n",
    "synsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'distance travelled per unit time'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synsets[0].definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('rate.n.01')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypernyms = synsets[0].hypernyms()\n",
    "hypernyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a magnitude or frequency relative to a time unit'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypernyms[0].definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('san_diego.n.01')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = \"San_diego\"\n",
    "synsets = wn.synsets(word)\n",
    "synsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a picturesque city of southern California on San Diego Bay near the Mexican border; site of an important naval base'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synsets[0].definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypernyms = synsets[0].hypernyms()\n",
    "hypernyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a school for students intermediate between elementary school and college; usually grades 9 to 12'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hypernyms[0].definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paris.n.01 : the capital and largest city of France; and international center of culture and commerce\n",
      "  상위개념:\n",
      "paris.n.02 : sometimes placed in subfamily Trilliaceae\n",
      "  상위개념:\n",
      "  plant_genus.n.01 : a genus of plants\n",
      "paris.n.03 : (Greek mythology) the prince of Troy who abducted Helen from her husband Menelaus and provoked the Trojan War\n",
      "  상위개념:\n",
      "paris.n.04 : a town in northeastern Texas\n",
      "  상위개념:\n"
     ]
    }
   ],
   "source": [
    "for synset in synsets:\n",
    "    print(f\"{synset.name()} : {synset.definition()}\")\n",
    "    \n",
    "    # 상위개념 찾기\n",
    "    hypernyms = synset.hypernyms()\n",
    "    print(\"  상위개념:\")\n",
    "    for hypernym in hypernyms:\n",
    "        print(f\"  {hypernym.name()} : {hypernym.definition()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sj_virtual",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
